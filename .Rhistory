data <- read.csv("UCI_Credit_Card.csv")
head(data)
summary(data)
# import data
data <- read.csv("UCI_Credit_Card.csv")
# look at data
head(data)
summary(data)
# Using some of the data cleaning from kaggle website
# https://www.kaggle.com/moscolitos/d/uciml/default-of-credit-card-clients-dataset/exploratory-data-analysis#L39
# Make variables factors into factors
factor_vars <- c('SEX','EDUCATION','MARRIAGE','default.payment.next.month')
# make categorical variable factors by apply to each column
data[factor_vars] <- lapply(data[factor_vars], function(x) as.factor(x))
x = data$EDUCATION[data$EDUCATION == c(0,4,5,6)]
data$EDUCATION[data$EDUCATION== 4]         <- 0
data$EDUCATION[data$EDUCATION== 5]  <- 0
data$EDUCATION[data$EDUCATION== 6]  <- 0
length(x)
summary(data)
data2 <- data
data2$ID <- NULL
indexes <- sample(1:nrow(data), size = 0.2*nrow(data))
test <- data[indexes, ]
train <- data[-indexes, ]
set.seed(1)
# Test train split
source("MF850Utilities.R")
# Read data from source
data <- loadLaggedDataSet()
# Re move columns with NA
data <- na.omit(data)
# Observatoins per month
summary(data$Date)
# Not equal number of observations per month
# Create test set - the last month of observations
test_set <- data[data$Date == "2015-11-30", ]
y_test <- test_set$futurereturns
# Create train set - previous 2 months
# First take one month
train_set1 <- data[data$Date == "2015-10-31", ]
train_set2 <- data[data$Date == "2015-09-30", ]
# Combine two months for training set
train_set <- rbind(train_set1, train_set2)
y_train <- train_set$futurereturns
# Remove company id - (there should only be one per month)
test_set$compid <- NULL
train_set$compid <- NULL
# Remove Date
test_set$Date <- NULL
train_set$Date <- NULL
# Remove RETMONTH
test_set$RETMONTH <- NULL
train_set$RETMONTH <- NULL
# Remove SPX - unique per month
test_set$RETMONTH_SPX <- NULL
train_set$RETMONTH_SPX <- NULL
# Remove future returns (saved in previous variable)
test_set$futurereturns <- NULL
train_set$futurereturns <- NULL
# SCALE DATA
# Need to separate categorical variables
Industry_test <- (test_set$Industry)
Industry_train <- (train_set$Industry)
# Remove Industry from sets before we scale
pre_scale_test <- within(test_set, rm("Industry"))
pre_scale_train <- within(train_set, rm("Industry"))
# Scale the continous variable
test_set <- scale(pre_scale_test)
train_set <- scale(pre_scale_train)
#Create data frames
x_train <- as.data.frame(train_set)
x_test <- as.data.frame(test_set)
# Add industry to sets
x_train$Industry <- Industry_train
x_test$Industry <- Industry_test
# Train set for categorical analysis
y_train_cat <- ifelse(y_train > 0, 1, 0)
# Ratio of high vs low returns for TRAIN set
high_low_ratio_train <- sum(y_train_cat == 1)  / length(y_train_cat)
# Test set for categorical analysis
y_test_cat <- ifelse(y_test > 0, 1, 0)
# Ratio of high vs low returns for TEST set
high_low_ratio_test <- sum(y_test_cat == 1) / length(y_test_cat)
# A priori number to beat
# Baseline MSE for training set- pick the mean
MSE_train <- mean((y_train - mean(y_train)) ^ 2)
MSE_test <- mean((y_test - mean(y_train)) ^ 2)
# Test and training sets to csv
# write.csv(test_set, file = "Test_set.csv")
# write.csv(train_set, file = "Train_set.csv")
# Remove variables we will not need
# rm(data, train_set1, train_set2, pre_scale_test,
#    pre_scale_train, Industry_train, Industry_test,
#    train_set, test_set)
## Remove functions from Utilities
#rm(lagStockData, loadLaggedDataSet, loadpackages,
#   requiredpackages, laggedDataFile, mf850_finalproject_data)
# Practice set (without returns )
train_set3 <- data[data$Date == "2015-02-28", ]
train_set4 <- data[data$Date == "2015-01-31", ]
train_set5 <- rbind(train_set3, train_set4)
train_set_results <- train_set5$futurereturns
# Remove variables
train_set5$RETMONTH <- NULL
train_set5$futurereturns <- NULL
# Write results to file
#write.csv(train_set5, file = "TestDF_no_returns.csv")
#write.csv(train_set_results, file = "TestDF_returns.csv")
# import data
data <- read.csv("UCI_Credit_Card.csv")
# look at data
head(data)
summary(data)
# Data cleaning
# Using some of the data cleaning from kaggle website
# https://www.kaggle.com/moscolitos/d/uciml/default-of-credit-card-clients-dataset/exploratory-data-analysis#L39
# Make variables factors into factors
factor_vars <- c('SEX','EDUCATION','MARRIAGE','default.payment.next.month')
# make categorical variable factors by apply to each column
data[factor_vars] <- lapply(data[factor_vars], function(x) as.factor(x))
# Small amounts of educationn at these levels- combine to reduce dimensionality
x = data$EDUCATION[data$EDUCATION == c(0,4,5,6)]
length(x)
# Replace 3 educations with same value
data$EDUCATION[data$EDUCATION== 4]  <- 0
data$EDUCATION[data$EDUCATION== 5]  <- 0
data$EDUCATION[data$EDUCATION== 6]  <- 0
summary(data)
# Data looks ready for analysis
#############
## ANALYSIS
#############
set.seed(1)
data2 <- data
# Delete row unique identifier row ID
data2$ID <- NULL
# Split data into test and training sets
indexes <- sample(1:nrow(data), size = 0.2*nrow(data))
test <- data[indexes, ]
train <- data[-indexes, ]
#
# x_train <- model.matrix(L)
colnames(test)
x_train <- model.matrix(LIMIT_BAL~.)
x_train <- model.matrix(LIMIT_BAL~., data = train)
dim(x_train)
y_train <- train$LIMIT_BAL
x_train <- train
y_test <- test
x_test <- test
rm(data, data2, test, train, factor_vars, x, indexes)
# import data
data <- read.csv("UCI_Credit_Card.csv")
# look at data
head(data)
summary(data)
# Data cleaning
# Using some of the data cleaning from kaggle website
# https://www.kaggle.com/moscolitos/d/uciml/default-of-credit-card-clients-dataset/exploratory-data-analysis#L39
# Make variables factors into factors
factor_vars <- c('SEX','EDUCATION','MARRIAGE','default.payment.next.month')
# make categorical variable factors by apply to each column
data[factor_vars] <- lapply(data[factor_vars], function(x) as.factor(x))
# Small amounts of educationn at these levels- combine to reduce dimensionality
x = data$EDUCATION[data$EDUCATION == c(0,4,5,6)]
length(x)
# Replace 3 educations with same value
data$EDUCATION[data$EDUCATION== 4]  <- 0
data$EDUCATION[data$EDUCATION== 5]  <- 0
data$EDUCATION[data$EDUCATION== 6]  <- 0
summary(data)
# Data looks ready for analysis
#############
## ANALYSIS
#############
set.seed(1)
data2 <- data
# Delete row unique identifier row ID
data2$ID <- NULL
# Split data into test and training sets
indexes <- sample(1:nrow(data), size = 0.2*nrow(data))
test <- data[indexes, ]
train <- data[-indexes, ]
# Split training data into response and x data
y_train <- train$LIMIT_BAL
x_train <- train
x_train$LIMIT_BAL <- NULL
# Split test data into response and x data
y_test <- test$LIMIT_BAL
x_test <- test
x_test$LIMIT_BAL <- NULL
# remove other variables
rm(data, data2, test, train, factor_vars, x, indexes)
source("clean_and_split.R")
requiredpackages <- "glmnet"
loadpackages(requiredpackages)
data_train = data.frame(cbind(y_train, x_train))
library(glmnet)
data_train = data.frame(cbind(y_train, x_train))
fit_all <- glm(y_train_cat~., data = data_train)
summary(fit_all)
fit_all <- glm(y_train~., data = data_train)
data_train = data.frame(cbind(y_train, x_train))
fit_all <- glm(y_train~., data = data_train)
summary(fit_all)
(MSE_all_train <- mean((fit_all$fitted.values - y_train) ^ 2))
MSE_train
((MSE_train - MSE_all_train)/MSE_train)*100
names(fit_all)
?glm
fit_all$R
fit_all <- lm(y_train~., data = data_train)
summary(fit_all)
x = model.matrix(y_train ~., data = data_train)
lambdas <- 10^seq(-5, 3, length = 100)
cv.lasso = cv.glmnet(x, y_train, type.measure = "mse",
lambda = lambdas, alpha = 1, standardize = FALSE)
cv.ridge = cv.glmnet(x, y_train, type.measure = "mse",
lambda = lambdas, alpha = 0, standardize = FALSE)
lasso_lambdas <- cv.lasso$lambda
lasso_cv_means <- cv.lasso$cvm
plot(lasso_lambdas, lasso_cv_means, main = "Lasso Lambda vs Cross Validation MSE", log = "x")
ridge_lambdas <- cv.ridge$lambda
ridge_cv_means <- cv.ridge$cvm
plot(ridge_lambdas, ridge_cv_means, main = "Ridge Lambda vs Cross Validation MSE", log = "x")
numb_alphas <- 20
lambda_cv_min <- data.frame(matrix(0, nrow = numb_alphas, ncol = 3))
names(lambda_cv_min)[1:3] <- c("Lambda", "Min CV", "Alpha")
for (alpha_n in 1:numb_alphas){
# New alpha
alpha <- alpha_n * (1 / numb_alphas)
# Run Ridge/Lasso Mix
cv.temp = cv.glmnet(x, y_train, type.measure = "mse",
lambda = lambdas, alpha = alpha, standardize = FALSE)
# Store min cvm
min_cv_temp <- min(cv.temp$cvm)
# Store lambda for min cvm
lambda_temp <- cv.temp$lambda.min
# Store in alpha, lambda, min cv in data frame
lambda_cv_min[alpha_n, c(1:3)] <- c(lambda_temp, min_cv_temp, alpha)
}
min_cv_best <- min(lambda_cv_min$`Min CV`)
(best_row <- lambda_cv_min[which(lambda_cv_min$`Min CV` == min_cv_best), ])
plot(lambda_cv_min$Alpha, lambda_cv_min$`Min CV`)
CV_alpha_fit <- lm(`Min CV` ~ Alpha, data = lambda_cv_min)
abline(CV_alpha_fit, col = "blue", lwd = 3)
((best_row$`Min CV`-MSE_train)/MSE_train)*100
glm_best <- glmnet(x, y_train, alpha = best_row$Alpha,
standardize = FALSE, lambda = lambdas)
glm_best_coef <- predict(glm_best, type = "coefficients",
s = best_row$Lambda)[1:(ncol(x)), ]
sort(glm_best_coef[abs(glm_best_coef) > 0.1])
length(glm_best_coef[abs(glm_best_coef) > 0.1])
x2 <- data.frame(cbind(y_test, x_test))
x_train_edit <- model.matrix(y_test ~., data = x2)
predict_glm <- predict(glm_best, newx = x_train_edit,
type = "response", s = best_row$Lambda)
(MSE_glm_test <- mean((predict_glm - y_test)^2))
MSE_train
((MSE_train - MSE_glm_test)/MSE_train)*100
summary(fit_all)
names(fit_all)
names(summary(fit_all))
sort(glm_best_coef[abs(glm_best_coef) > 0.1])
MSE_all_train/MSE_glm_test
